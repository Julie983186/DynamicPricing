import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error
import re
import joblib

# -----------------------------
# 1ï¸è®€å–è³‡æ–™
# -----------------------------
df = pd.read_csv("ç•¢æ¥­å°ˆé¡Œç”°é‡èª¿æŸ¥.csv", encoding="utf-8-sig")
# -----------------------------
# ğŸ”¹å°‡å‰©é¤˜ä¿å­˜æœŸé™(å¤©) + æ™‚é–“ç´°åŒ–æˆå°æ™‚
# -----------------------------

def compute_remaining_hours(row):
    # å‰©é¤˜ä¿å­˜æœŸé™ï¼ˆå¤©è½‰å°æ™‚ï¼‰
    hours = row['å‰©é¤˜ä¿å­˜æœŸé™'] * 24

    # å¾æ™‚é–“æ¬„ä½ä¸­å–å‡ºã€ŒçµæŸæ™‚é–“ã€çš„æ™‚æ•¸
    time_str = str(row['æ™‚é–“'])
    match = re.search(r'(\d{1,2}):\d{2}-(\d{1,2}):\d{2}', time_str)
    if match:
        end_hour = int(match.group(2))
    else:
        end_hour = 0  # é˜²å‘†

    # è¨ˆç®—ä»Šæ—¥å‰©ä¸‹å¹¾å°æ™‚ï¼ˆå‡è¨­æ¯å¤©24:00çµæŸï¼‰
    remaining_today = 24 - end_hour

    # ç¸½å‰©é¤˜æ™‚é–“ï¼ˆå–®ä½ï¼šå°æ™‚ï¼‰
    total_hours = hours + remaining_today
    return total_hours

# æ–°å¢æ¬„ä½ï¼šå‰©é¤˜ä¿å­˜æœŸé™_å°æ™‚
df['å‰©é¤˜ä¿å­˜æœŸé™_å°æ™‚'] = df.apply(compute_remaining_hours, axis=1)

print(df[['æ™‚é–“', 'å‰©é¤˜ä¿å­˜æœŸé™', 'å‰©é¤˜ä¿å­˜æœŸé™_å°æ™‚']].head())
# -----------------------------
# 2ï¸è¦å‰‡å‹æŠ˜æ‰£
# -----------------------------
def calc_rule_discount(row):
    hours = row['å‰©é¤˜ä¿å­˜æœŸé™_å°æ™‚']  # âœ… æ”¹ç”¨å°æ™‚è¨ˆç®—

    if row['å•†å“å¤§é¡'] == 'è‚‰é¡':
        if hours <= 6: return 0.6
        elif hours <= 12: return 0.45
        elif hours <= 24: return 0.3
        elif hours <= 48: return 0.15
        else: return 0

    elif row['å•†å“å¤§é¡'] == 'é­šé¡':
        if hours <= 6: return 0.5
        elif hours <= 12: return 0.35
        elif hours <= 24: return 0.25
        elif hours <= 48: return 0.1
        else: return 0

    elif row['å•†å“å¤§é¡'] == 'è”¬æœé¡':
        if hours <= 6: return 0.45
        elif hours <= 12: return 0.3
        elif hours <= 24: return 0.2
        elif hours <= 48: return 0.1
        else: return 0

    elif row['å•†å“å¤§é¡'] == 'éºµåŒ…ç”œé»é¡':
        if hours <= 6: return 0.4
        elif hours <= 12: return 0.25
        elif hours <= 24: return 0.15
        elif hours <= 48: return 0.05
        else: return 0

    elif row['å•†å“å¤§é¡'] == 'è±†è£½å“é¡':
        if hours <= 6: return 0.35
        elif hours <= 12: return 0.25
        elif hours <= 24: return 0.15
        elif hours <= 48: return 0.05
        else: return 0

    elif row['å•†å“å¤§é¡'] == 'ç†Ÿé£Ÿ/å…¶ä»–':
        if hours <= 6: return 0.3
        elif hours <= 12: return 0.2
        elif hours <= 24: return 0.1
        elif hours <= 48: return 0.05
        else: return 0

    elif row['å•†å“å¤§é¡'] == 'å…¶ä»–':
        if hours <= 6: return 0.25
        elif hours <= 12: return 0.15
        elif hours <= 24: return 0.1
        elif hours <= 48: return 0.05
        else: return 0

    else:
        return 0



df['æŠ˜æ‰£è¦å‰‡'] = df.apply(calc_rule_discount, axis=1)
df['å”®åƒ¹è¦å‰‡'] = df['åŸåƒ¹'] * (1 - df['æŠ˜æ‰£è¦å‰‡'])

# -----------------------------
# 3ï¸æº–å‚™æ©Ÿå™¨å­¸ç¿’ç‰¹å¾µ
# -----------------------------
# å°‡å•†å“å¤§é¡è½‰ç‚º One-Hot
# å°æ‰€æœ‰é¡åˆ¥æ¬„ä½åš One-Hot
df = pd.get_dummies(df, columns=['å•†å“å¤§é¡', 'åœè»Šç‹€æ³', 'äººæµé‡', 'å¤©æ°£'])
cols = [c for c in df.columns if '_' in c]
df[cols] = df[cols].fillna(0).astype(int)

# ç‰¹å¾µæ¬„ä½
feature_cols = ['å‰©é¤˜ä¿å­˜æœŸé™_å°æ™‚','åŸåƒ¹','ç•¶ä¸‹æº«åº¦','è²¨æ¶ä¸Šåº«å­˜é‡'] \
               + [c for c in df.columns if c.startswith('å•†å“å¤§é¡_')] \
               + [c for c in df.columns if c.startswith('åœè»Šç‹€æ³_')] \
               + [c for c in df.columns if c.startswith('äººæµé‡_')] \
               + [c for c in df.columns if c.startswith('å¤©æ°£_')]

X = df[feature_cols]
y = df['æŠ˜æ‰£è¦å‰‡']  # ç›£ç£å­¸ç¿’ç›®æ¨™ï¼šå­¸è¦å‰‡æŠ˜æ‰£

# -----------------------------
# 4ï¸æ‹†åˆ†è¨“ç·´/æ¸¬è©¦é›†
# -----------------------------
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# -----------------------------
# 5ï¸è¨“ç·´ Random Forest
# -----------------------------
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# é æ¸¬
y_pred = model.predict(X_test)
print("MSE:", mean_squared_error(y_test, y_pred))

# -----------------------------
# 6ï¸ç”¨æ¨¡å‹é æ¸¬æŠ˜æ‰£
# -----------------------------
df['æŠ˜æ‰£é æ¸¬'] = model.predict(X[feature_cols])
df['å”®åƒ¹é æ¸¬'] = df['åŸåƒ¹'] * (1 - df['æŠ˜æ‰£é æ¸¬'])
df['æŠ˜æ‰£é æ¸¬'] = df['æŠ˜æ‰£é æ¸¬'].round(2)
df['å”®åƒ¹é æ¸¬'] = df['å”®åƒ¹é æ¸¬'].round(0)
# -----------------------------
# 7ï¸æŸ¥çœ‹çµæœ
# -----------------------------
print(df[['å•†å“å“é …','å‰©é¤˜ä¿å­˜æœŸé™_å°æ™‚','æŠ˜æ‰£è¦å‰‡','å”®åƒ¹è¦å‰‡','æŠ˜æ‰£é æ¸¬','å”®åƒ¹é æ¸¬']])

# -----------------------------
# 8ï¸å­˜æª”
# -----------------------------
#df.to_csv("dynamic_pricing_result.csv", index=False)
output_path = "dynamic_pricing_result.csv"
df.to_csv(output_path, index=False, encoding="utf-8-sig")
print("å·²å­˜æª”ï¼šdynamic_pricing_result.csv")

# å„²å­˜æ¨¡å‹
model_path = "random_forest_model.pkl"
joblib.dump(model, model_path)
print("æ¨¡å‹å·²å„²å­˜ï¼š", model_path)
